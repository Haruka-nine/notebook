

# 导读

## 特征工程的作用

数据特征决定了模型的上限

预处理和特征提取是最核心的

算法和参数选择决定了如何逼近这个上限

## 如何提取特征？

这时机器学习的难点，如何提取特征，如何去选特征？人为的去找，很难

这就是传统机器学习的难点

## 为什么需要深度学习？

深度学习会自己提取特征

可以认为深度学习是一个黑盒子

将数据放入黑盒子，他会自动提取特征

也就是说深度学习解决了提取特征的难点

## 深度学习的问题

深度学习最大的问题就是速度

深度学习计算的量太大了，相比于逻辑回归的参数，深度学习参数太多了，就导致速度很慢

导致的就是移动端支持不是很好


# 计算机视觉

## 图像分类任务

（假设我们有一系列的标签，猫 ，狗，树 ，汽车， 飞机），需要判断出哪个是猫

图像表示：计算机中的图像被表示成三维数组的形式，每个像素值从0到255

例如 `300*100*3`

代表 300长，100宽 ，rgb分别占3个

## 面临的挑战

照射角度：
不同的角度，会导致不同的结果

正面照片和夜市中的侧面照片肯定不一样

遮蔽情况：

![[Pasted image 20230405200431.png]]

背景混入：
![[Pasted image 20230405200450.png]]


## 机器学习常规套路

1. 收集数据并给定标签
2. 训练一个分类器
3. 评测，评估

### 传统算法-视觉任务

k近邻算法：
![[Pasted image 20230405200745.png]]

数据：两类点方块和三角

绿色的点属于方块还是三角呢？

K = 3 还是K = 5?结果一样吗？

但这时，K = 3和K = 5时不一样的

我们如果使用K近邻来进行图像分类任务
![[Pasted image 20230405201245.png]]

![[Pasted image 20230405201302.png]]

可以看到一坨答辩


### 为什么K近邻不能用来图像分类

背景主导是一个很大的问题，我们关注的是主体（主要成分）

如何才能让机器学习到那些是重要的成分呢？


# 神经网络


## 基础

### 线性函数

从输入到输出的映射

![[Pasted image 20230405202002.png]]
这只猫是`32*32*3`

每个像素点的权重参数w是不一样的

我们可以认为

共3072个像素点，权重就是一个3072行向量，image就是一个3072列向量，相乘可以得到一个的得分值

f(x,W) = Wx   (+b)

b是一个微调参数，我们可以对每个类型进行微调

如果对于一个10分类。

10个分类就是10个权重参数，并且10个b对其分别进行微调

然后我们就可以得到10个得分



这里给出一个三分类进行示例
![[Pasted image 20230405202928.png]]



```ad-note
我们可以看到一个问题，这是一个猫的图像，但猫的得分却是负的？

我们可以看到X是固定的，那么我们可以改变W

这就是神经网络做的事情，**在训练中不断改变W的值，不断调整，使其符合事实**
```

### 损失函数

我么可以看到，上方的线性函数并不好

那么到底哪里不好？有多么不好？

这就是损失函数的作用

损失函数示例

![[Pasted image 20230405203743.png]]
![[Pasted image 20230405203754.png]]

Sj -Syi就是错误类别减去正确类别， 1就是一个容忍程度

我们可以看到，只有错误类别得分比正确类别得分高1时，L 才会大于0
如果我们设置成10，那么只有差别达到10时，L 才会大于0

L就是损失值，做的不好就有损失，做的好就会损失

我么可以算出猫的损失值为2.9，而车很好，损失值为0


```ad-question
如果损失函数的值相同，那么意味着两个模型一样吗
```

![[Pasted image 20230405204613.png]]

输入数据：
![[Pasted image 20230405204629.png]]

两个模型：
![[Pasted image 20230405204650.png]]


但我们可以看到一个问题，模型A只考虑第一部分(只关注局部，过拟合)，而模型B趋于稳定

但这两个得到了相同的损失

解决方法就是正则化惩罚项

![[Pasted image 20230405205000.png]]


正则化惩罚项越大更容易杀死过拟合

```ad-note
神经网络的缺点就是太强大了，很容易过拟合
我们应该关注如何让其弱一点
过拟合可以理解为可以完美处理训练集里的东西，但一碰上测试集就GG
```

### Softmax分类器

现在我们得到的是一个输入的得分值，但直接给我一个概率值不是更好？

如何把一个得分值换换成一个概率值？
![[Pasted image 20230405205956.png]]

通过这个sigmod函数就可以得出一个概率值

![[Pasted image 20230405210713.png]]

我们将得分 先exp就是e的x次方进行放大，然后进行归一化normalize,转换成概率。
我们肯定希望概率越接近1越好，这里可以进行一次-log，这个就是损失，因为没有损失时就是0

通常我们写一个损失函数，都是使用这个对数损失函数来做


### 向前传播

![[Pasted image 20230405205624.png]]

我们计算出得分值，然后算出损失值，然后加上正则化惩罚，得到我么当前的损失

```ad-question
如何更新模型？交给反向传播（梯度下降）
```




### 反向传播


```ad-note
首先，我们上面的得分是经过一层W

我们可以使用多层W对其计算，每层W关注的点不一样，形成多层梯度
```

![[Pasted image 20230406212837.png]]

正向传播我们得到的是

`f(x,y,z) = (x+y)*z`

那么反向传播我们就是对f求偏导，求出他对x,y,z的关系


梯度的反向计算：

加法门单元：均等分配

MAX门单元：给最大的

乘法门单元：互换的感觉

![[Pasted image 20230406213932.png]]



## 整体架构


![[Pasted image 20230406214229.png]]


**神经网络是一层一层办事的**


**神经元**就是特征，如果输入的数据有age ,weight,heigh三个参数，那么就是三个特征，三个神经元

但如果我们使用那张小猫的图片，`32*32*3` ,一共有3072个像素点，那就有3072个特征，就是3072个神经元

我们可以看到每个input layer的神经元都和每个hidden layer的每个神经元链接，这就是**全连接**

input layer只有三个特征，而hidden layer1却变成了4个特征，这就是神经网络计算的得到的。

如何变化？就是使用权重参数矩阵W

比如上方的图中，input layer是1×3，如何变换为 1×4，就是乘了一个3×4的矩阵
这个3×4的矩阵就是W1

如果我们觉得一个权重矩阵提取不够，我们再乘一个4×4的矩阵W2，就可以得到hidden layer2

最后得到output ,我们就需要乘一个4×1矩阵W3

```ad-note
根据上方我们可以知道，最后的output好不好，全看权重矩阵W1,W2,W3
```

**非线性** ：  
`x*W1*W2*W3 = OUT`

那么我们能不能使用使用一个`w4 = w1*w2*w3`直接代替呢？

答案是不能，因为在每一步之前并不会直接乘下一级的w

而是先对其进行一步非线性变换，比如max(a,x),sigmod,然后再进行下一级w

**所以我们必须一步一步的进行**

![[Pasted image 20230406220850.png]]



## 神经元个数的影响

神经元个数越多，过拟合程度越大，在经验集上效果越好，计算实验越长


## 激活函数

我们上边说了，经过权重参数变换后，还要乘一个非线性的激活函数

常用的激活函数

Sigmoid,Relu,Tanh

![[Pasted image 20230407063533.png]]

Sigmoid现在已经不用了，因为在两边，他的梯度约等于0了（**梯度消失**）

因为梯度是乘的关系，所以一旦其中有个梯度为0，就会导致最终梯度消失

Relu激活函数解决了这个问题 max(0,x),在大于0梯度为1，小于0直接除掉


## 数据预处理

不同的数据预处理结果会使得模型的效果发生很大的差异

![[Pasted image 20230407064059.png]]


一般我们都要进行图中的初始化，数据中心化，维度放缩或者扩充

## 参数初始化

参数初始化同样非常重要

通常我们都是使用随机策略来进行参数初始化

![[Pasted image 20230407064729.png]]


## DROP -OUT(传说中的七伤拳)

过拟合是神经网络非常头疼的一个大问题

![[Pasted image 20230407065707.png]]


B图就是在每一层的神经元中随机的杀死几个神经元，我们要经过多次迭代

每次迭代我们都随机的杀死每层的部分神经元，以减少过拟合

比如DROP-OUT使用50%，就是每层杀死一半，每次只使用每层的一半神经元

# 卷积神经网络

## 简介

![[Pasted image 20230408154156.png]]

我们可以看到，传统的神经网络是一个平面，而卷积网络是一个**三维立体的**。不难发现，卷积网络中多了一个概念--深度。例如图像输入数据h×w×c,其中颜色通道c就是输入的深度

```ad-note
在使用tensorflwo做神经网络时，先将图像拉成像素点组成的特征,这样相当于输入一行特征而非一个原始图像数据
而卷积中要操作的对象是一个整体，所以需要定义深度
```

卷积就是一种特征提取的方法

![[Pasted image 20230408154626.png]]
以前是对每个像素点进行处理，独立的对待每个像素点，但图像中的像素点是由一定的连续关系的
我们以前就舍弃了这种连续关系

卷积就是按区域进行划分，对每个区域进行特征提取应当更合理


![[Pasted image 20230408154839.png]]

如图19-7，使用5×5×3的filter对32×32×3的图进行特征提取，就可以得到一张特征图

但图上为什么是两张？因为可以使用多种特征提取方法，也就是filter可以有多个，每个filter对应一张特征图，filter就对应我们的权重参数

![[Pasted image 20230408155121.png]]

![[Pasted image 20230408155232.png]]

```ad-note
在基本神经网络中，用多个隐藏层进行特征提取，卷积神经网络也是如此，只不过用的是卷积层
```


## 卷积计算方法

假如输入数据的大小为7×7×3（图像长度为7；宽度为7；颜色通道为RGB）

选择filter大小为3×3×3(参数需要自己设计，长3，宽3，3对应3颜色通道)

**输入数据的颜色通道数要和filter一样，都是3个，这点是卷积操作中必须成立的**，因为需要对应计算

![[Pasted image 20230408160130.png]]
![[Pasted image 20230408160149.png]]

计算完第一个区域，下一个计算区域在哪里？

区域的选择与滑动窗口差不多，需要指定滑动的步长，以依次选择特征提取区域

![[Pasted image 20230408160312.png]]

继续滑动窗口，直到最后一个位置,这样就得到一个特征图

通常依次卷积操作都希望能得到更多的特征，所以一个特征图肯定不够，这里选择两个filter

不同的filter权重参数各不相同，得到的特征图也肯定不同，相当于用多种方式得到不同的特征表示，再把他们堆叠到一起，就完成了全部卷积操作

## 卷积涉及参数

### 卷积核（filter）

卷积操作中最关键的就是卷积核，它决定最终特征提取的效果，需要设计其**大小与初始化方法**

大小即长和宽，对应输入的每一块区域。

保持数据大小不变，如果选择较大的卷积核，则会导致最终的特征较少，相当于在很粗糙的一大部分区域中寻找特征代表，而没有深入细节。所以，现阶段在设计卷积核时，基本都是使用较小的长和宽，目的时得到更细致（数量更多）的特征

一般来所，一种特征提取方法能够得到一个特征图，通常每次卷积操作都会使用多种提取方法，也就是多来几个卷积核，只要它们权重值不一样，得到的结果也不一样。

**一般256，512都是常见的特征图个数，对参数初始化来说，它和传统神经网络差不多，最常见的还是使用随机高斯初始化。**

### 步长（stride）

在选择特征提取区域时，需要指定每次滑动单元格的大小，也就是步长。

如果步长比较小，意味着要慢慢的尽可能多的选择特征提取区域，这样得到的特征图信息也会比较丰富。

如果步长较大，选中的区域就会变少，得到的特征图也会比较小

```ad-note
可以发现，步长会影响最终特征图的规模。在图像任务中，如果属于非特征处理任务（文本数据中的步长可表示为一次考虑多少上下文信息），最好选择小一点的步长，虽然计算多了一些，但可利用的特征丰富了，更有利于计算机完成识别任务
```

```ad-info
现阶段大家看到的网络模型步长基本都为1，可以认为是科学家公认的结果。
```

### 边界填充（pad）

首先考虑一个问题，在卷积不断滑动的过程中，每个像素点的利用情况是同样的吗？

边界上的像素点可能只被滑动一次，也就是只能参与一次计算，对特征图的贡献较小，非边界的点，可能被多次滑动，对特征图贡献较大。

这似乎有些不公平，因为我们并没有说边界上的点不重要

![[Pasted image 20230408162351.png]]

此时图片的输入为5×5，由于加了一圈0，所以变成了7×7。为什么填充0？为了结果的可靠性，0对计算结果没有很大影响。

### 特征图规格计算

当执行完卷积操作后会得到特征图，那么如何计算特征图的大小？只要给定上述参数，就能直接进行计算

![[Pasted image 20230408162748.png]]


在卷积网络中，曾举例计算全连接方式所需的权重参数，一般为千万级别，这实在过于庞大。
卷积神经网络中，不仅特征提取方式与传统神经网络不同，参数的级别也差几个量级

卷积操作中使用参数共享原则，在每一次迭代时，对所有区域使用相同的卷积核计算特征。
可以把卷积这种特征提取方式看成与位置无关的。
其中隐含的原理是：图像的一部分统计特性与其他部分是一样的。这意味着在这一部分学习的特征也能用在另一部分上。

```ad-note
一般来讲，用不同的卷积核提取不同区域的特征应当更合理，但是这样以来，计算的开销就太大了，要综合考虑。
```

![[Pasted image 20230408163937.png]]

```ad-info
观察可以发现，卷积涉及的参数和输入图像大小并无直接关系，这可解决了大问题，可以快速高效的完成图像处理任务
```

## 池化层

池化层也是卷积神经网络中非常重要的组成部分

![[Pasted image 20230408202640.png]]

假设把输入（224×224×64）当作某次卷积后的特征图结果
（池化层基本都是放到卷积层后使用的）

经过上图的池化后，给人的直观感觉就是特征图缩水了，高度和宽度都只有原来的一半，体积变成了四分之一，但是特征图个数保持不变。

```ad-note
但并不是所有的池化操作都会使得特征图长度、宽度变为原来的一半，需根据指定的步长和区域大小进行计算，但是通常“缩水”成一半的池化最常用
```

池化层的作用就是要**对特征图进行压缩**，因为卷积后得到太多特征图，能全部利用肯定最好，但计算量和涉及的权重参数随之增多，不得不采取池化方法进行特征压缩。常见的池化方法有最大池化和平均池化

---
最大池化

最大池化很简单，首先在输入特征图中选择各个区域，然后“计算”其特征值，这里并没有像卷积层那样有实际的权重参数进行计算，而是直接选择最大的数值即可
比如在图中左上角[1,1,5,6]区域中，经过最大池化操作得到的特征值就是6
![[Pasted image 20230408203527.png]]

---
平均池化

平均池化只不过在计算过程中，不取最大值而是取平均值
[1,0,3,4]区域得到特征值就是2

---
在池化操作中，依然需要指定参数，通常需要指定滑动窗口的步长（stride）和选择区域的大小（例如2×2，只有大小，没有参数）

```ad-note
最大池化感觉是做法独特，只拿最大的特征值，而平均池化更温柔一些，会综合考虑所有特征值，那么，是不是平均池化效果更好呢？并不是
现阶段使用的基本都是最大池化，感觉它和自然界中的优胜劣汰差不多，只会把最合适的保留下来，在神经网络中也是如此，需要最突出的特征。
```

**池化层的操作非常简单，因为并不涉及实际的参数计算，通常都是接在卷积层后面，卷积操作会得到较多的特征图，让特征更丰富，池化操作会压缩特征图大小，利用最有价值的特征。**


# 数据增强

深度学习中最依赖的就是数据量，对一只猫镜像，就是另一张图片
![[Pasted image 20230410103339.png]]

包括旋转，放大缩小

# 迁移学习

别人使用100w的图片去训练出了一个模型去识别某个物体

我也想识别某个物体，但我的图片只有1000个，太少了。

我和这个人的识别物体相同或者相似，那么我可以使用这个人的模型的权重进行初始化
